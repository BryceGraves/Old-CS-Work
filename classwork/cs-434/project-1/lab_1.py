# -*- coding: utf-8 -*-
"""Lab 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tO6uXFugj7O_n39Hiv7VkjmQO60IP1tY

# Programming Lab 1 - Data Science

***
# CS 434 - Dating Mining and Machine Learning
# Oregon State University-Cascades
***

# Instructions

# Section Code
* Complete the four sections below. They roughly correspond to Activities 1-4, respectively.

* Add all your `import` packages only within the top `Load packages` block.

* Break large chucks of code into consecutive smaller code blocks.

* For each task, provide your code. And finish each task with a tangible output/result, either `display`/`print` or a graph.

* Comment your work: either within the code or as text blocks above.

# Section Report
* For each section, complete the mini-report. Answer the question with **complete sentences**, graphs, tables, and/or code blocks with `print`.

* Replace the *Lorem ipsum* text with your answers (but leave the *Student Response* header).

* Answer each Report question individually each in separate (1+) text/code block(s).

* You can intersperse text and code blocks, as you like/need.


* *Take pride in visual appeal of your answers.* Format your responses nicely. Review the markup tutorial in `Lecture 00-Getting Started`.

# or smaller to stay within the `Student Response` section.
* If you use subsection headers, makes sure to use

***
# Load packages
***

Add the packages you need here (not below!)
"""

import seaborn as sns
from sklearn import metrics
import pandas as pd
import numpy as np
import urllib
import ssl
import matplotlib.pyplot as plt

from sklearn.base import clone
from itertools import combinations
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.preprocessing import MinMaxScaler

ssl._create_default_https_context = ssl._create_unverified_context

# Class from lecture 4


class SBS():
    def __init__(self, estimator, k_features, scoring=accuracy_score,
                 test_size=0.25, random_state=1):
        self.scoring = scoring
        self.estimator = clone(estimator)
        self.k_features = k_features
        self.test_size = test_size
        self.random_state = random_state

    def fit(self, X, y):

        X_train, X_test, y_train, y_test = \
            train_test_split(X, y, test_size=self.test_size,
                             random_state=self.random_state)

        dim = X_train.shape[1]
        self.indices_ = tuple(range(dim))
        self.subsets_ = [self.indices_]
        score = self._calc_score(X_train, y_train,
                                 X_test, y_test, self.indices_)
        self.scores_ = [score]

        while dim > self.k_features:
            scores = []
            subsets = []

            for p in combinations(self.indices_, r=dim - 1):
                score = self._calc_score(X_train, y_train,
                                         X_test, y_test, p)
                scores.append(score)
                subsets.append(p)

            best = np.argmax(scores)
            self.indices_ = subsets[best]
            self.subsets_.append(self.indices_)
            dim -= 1

            self.scores_.append(scores[best])
        self.k_score_ = self.scores_[-1]

        return self

    def transform(self, X):
        return X[:, self.indices_]

    def _calc_score(self, X_train, y_train, X_test, y_test, indices):
        self.estimator.fit(X_train[:, indices], y_train)
        y_pred = self.estimator.predict(X_test[:, indices])
        score = self.scoring(y_test, y_pred)
        return score


"""***
# Dataset
***
"""

dat_url = '../data/genes-leukemia.csv'
dat_description = '../data/genes-leukemia-description.txt'

"""Print out the provided description of the dataset."""

# # run this
# data = urllib.request.urlopen(dat_description)
# for line in data:
#     print(line.decode("utf-8").replace('\n', ''))

with open(dat_description, 'r') as fin:
    print(fin.read())

"""***
# Task 1: Data Exploration
***

# 1.1 Load and display data
"""

df = clean_df = df = pd.read_csv(dat_url)
print(df)

"""### 1.2 Identify which features have missing data"""

print(df.isin(['?']).sum())

"""### 1.3 Convert all missing values to `NaN`"""

clean_df = df.applymap(lambda x: pd.NA if x == '?' else x)

"""### 1.4 Drop unique columns

Drop any columns that are not features.  That is to say it was a unique value for each example (and thus conveys no information).
"""

to_drop = []

for index, value in clean_df.nunique().items():
    if value == 72:
        to_drop.append(index)

clean_df.drop(columns=to_drop, inplace=True)

"""***
# <img src="https://img.icons8.com/color/32/000000/new-document.png"/> Section 1 - Report

Answer the following questions below:
1. How many records are there?

72 records

2. How many features are there?

51

3. How many features are continuous?

43

4. How many features are nominal (exclude class label)?

# TODO: double check this
5

5. How many `NaN` values are there?

259

6. Which columns did you drop in Task `1.4`?

['SNUM', 'M91432', 'U32944', 'D38073', 'M84371_rna1_s', 'M31523', 'U29175']

# <img src="https://img.icons8.com/color/32/000000/speech-bubble-with-dots.png"/> **Student Response**

*Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum*

***
# Task 2 - Data Cleaning
***

# 2.1 Fix the feature `Gender`

Map the unknowns to a string label `U` to add to the existing values `{M, F}`
"""

clean_df['Gender'] = clean_df['Gender'].fillna('U')

"""### 2.2 Merge the features `TB_if_ALL` and `FAB_if_AML`

These represent two types of tests. `TB_if_ALL` has values `{'T-cell', 'B-cell'}`. Whereas `FAB_if_AML` has values such as `M1`, `M2`, etc. 

Let's combine them into once column `TB_FAB` that has the values of `{'T-cell', 'B-cell', 'M'}`.

> Note we set any value `M1`, `M2`, `M3` to be just `M`.

Once you have combined the columns `TB_if_ALL` and `FAB_if_AML` into `TB_FAB` successfully, you can drop the original columns `TB_if_ALL` and `FAB_if_AML` (and keep the combined column).
"""

clean_df['FAB_if_AML'] = clean_df['FAB_if_AML'].replace(
    to_replace=r'(M\d)', value='M', regex=True)

clean_df['TB_FAB'] = clean_df['TB_if_ALL'].combine_first(
    clean_df['FAB_if_AML'])

clean_df.drop(columns=['TB_if_ALL', 'FAB_if_AML'], inplace=True)

"""### 2.3 Drop certain rows depending on `TB_FAB`

For any record still missing from the merged `TB_FAB` feature, drop that entire row.
"""

clean_df.dropna(subset=['TB_FAB'], inplace=True)

"""### 2.4 Drop or Impute?

For any each other column missing data, check to see what percent of records are missing values.

1. `if` the missing records are more than $1/3$ of all values, drop the column
2. `else` impute the mean value for the column
"""

to_drop = []

for index, value in clean_df.isnull().mean().items():
    if value > (0.33):
        to_drop.append(index)

clean_df.drop(columns=to_drop, inplace=True)
clean_df.fillna(clean_df.mean(), inplace=True)

"""### 2.5 Convert categorical data to ordinal values"""

columns = clean_df.select_dtypes(['object']).columns
clean_df[columns] = clean_df[columns].astype('category')
clean_df[columns] = clean_df[columns].apply(lambda x: x.cat.codes)

"""***
# <img src="https://img.icons8.com/color/32/000000/new-document.png"/> Section 2 - Report

Answer the following questions below:
1. Provide the counts for `Gender` for each `{'M', 'F', 'U'}`.

M    26
F    23
U    23

2. Provide the counts for `TB_FAB` for each `{'T-cell', 'B-cell', 'M'}`.

B-cell    38
M         20
T-cell     9

3. Explain how you went about merging to produce `TB_FAB`.

I first replaced the iterative m values in FAB_if_AML with just M. Then I used combine first to combine FAB_if_AML into TB_if_ALL when TB_if_ALL was null.
I then assigned that to the new column and dropped the other two.

4. How many rows did you drop that were missing a `TB_FAB` value?

5

5. Which columns did you drop?  Which did you impute?

Dropped: ['Year', 'pct_Blasts', 'Treatment_Response']
Imputed: []

6. Which columns did you convert from categorical to ordinal?

['CLASS', 'BM_PB', 'Gender', 'Source', 'TB_FAB']

# <img src="https://img.icons8.com/color/32/000000/speech-bubble-with-dots.png"/> **Student Response**

*Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum*

***
# Section 3 - Datasets
***

# 3.1 Encode the class label
"""

# This is already encoded above

"""### 3.2 Split features and labels"""

X, y = clean_df.iloc[:, 1:].values, clean_df.iloc[:, 0].values

"""### 3.3 Partition train and test (0.3) sets"""

X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.3,
                                                    random_state=0,
                                                    stratify=y)

"""### 3.4 Normalize your numeric features"""

mms = MinMaxScaler()
X_train = mms.fit_transform(X_train)
X_test = mms.transform(X_test)

"""***
# <img src="https://img.icons8.com/color/32/000000/new-document.png"/> Section 3 - Report

Answer the following questions below:
1. How many unique values are there for the class label column?

2

2. How many features are left (after previous cleaning steps)?

39

3. How many records are in the train set? test set?

Train: 46
Test: 21

4. `[Code]` In one table, `describe` five adjacent columns
  * begin with `D49950` and consider the four next columns

start = clean_df.columns.get_loc('D49950')
end = start + 5

print(clean_df.iloc[:, start:end].describe())

# <img src="https://img.icons8.com/color/32/000000/speech-bubble-with-dots.png"/> **Student Response**

*Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum*

***
# Task 4 - Feature importance
***

# 4.1 Log transform all features (but not class label)

Select only the dytpes of `float64`.
"""

# Convert ndarray to dataframe
train_as_df = pd.DataFrame(X_train)
test_as_df = pd.DataFrame(X_test)

# Lets see what dtypes we have all types that are non 64 base are ordinal
print(clean_df.dtypes)

# Pull out non ordinal columns to log transform
# I pull these from the clean_df since they are all float64 in their train and test sets
columns = clean_df.select_dtypes(['float64', 'int64']).columns

# Map the column names to their numerical index
index = [clean_df.columns.get_loc(column) for column in columns]


# Log transform pulled index locations then reapply them to their respective dataframe
train_as_df[index] = np.log1p(train_as_df[index])
test_as_df[index] = np.log1p(test_as_df[index])

# Convert back to numpy arrays
X_train = train_as_df.values
X_test = test_as_df.values

# A TRAIN SET?!
print('X train set: ', X_train)
print('X test set: ', X_test)

"""### 4.2 Feature discretization

Perform both *equal-width* and *equal-frequency* binning approaches for $n=5$ bins. Compare your bins and decide which is better for this data. Make a decision and apply that approach to our data.
"""

# equal width
# create 10 equal width bins
discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')
discretizer.fit(X_train)
X_train_equal_width = discretizer.transform(X_train)
X_test_equal_width = discretizer.transform(X_test)

for i in range(0, 5):
    print('bin', i, ':', np.count_nonzero(X_train_equal_width == i))

# equal frequency
discretizer = KBinsDiscretizer(
    n_bins=5, encode='ordinal', strategy='quantile')
discretizer.fit(X_train)
X_train_equal_frequency = discretizer.transform(X_train)
X_test_equal_frequency = discretizer.transform(X_test)

for i in range(0, 5):
    print('bin', i, ':', np.count_nonzero(
        X_train_equal_frequency == i))

"""### 4.3 Feature selection

Use Sequential Feature Selection (with `kNN` where $k=3$) to inform how many features you should retain. Graph the feature importance. Make a decision about your cut-off point. Decide how many $N$ features you will select.
"""

knn = KNeighborsClassifier(n_neighbors=5)

# selecting features
sbs = SBS(knn, k_features=1)
sbs.fit(X_train_equal_frequency, y_train)

# plotting performance of feature subsets
k_feat = [len(k) for k in sbs.subsets_]

# plt.plot(k_feat, sbs.scores_, marker='o')
# plt.ylim([0.7, 1.02])
# plt.ylabel('Accuracy')
# plt.xlabel('Number of features')
# plt.grid()
# plt.tight_layout()
# plt.show()

"""### 4.4 Model evaluation

Determine the training and test accuracies for 
1. all features
2. the best $N$ selected features.
"""

# how many susbsets
len(sbs.subsets_)

# consider best three features
features = list(sbs.subsets_[-4])


sns.pairplot(clean_df.iloc[:, features])
plt.title('Pearplot')
plt.show()

"""***
# <img src="https://img.icons8.com/color/32/000000/new-document.png"/> Section 4 - Report

Answer the following questions below:
1. Which discretization approach did you choose? equal-width or equal-frequency? Why?

I went with frequency mainly because the distribution seemed more natural compared to that of equal width.
Many of the train and test sets were trained up to a value above the test or to a max of 1 which felt fishy.

2. How many features did you select?  Why did you determine that particular value for $N$?

I selected 4 because it matched the desired output of a lower training score instead of training up and being over fit.

3. `[Plot]` Make a pair-plot of your $N$ selected features.

```python
sns.pairplot(clean_df.iloc[:, features])
plt.title('Pearplot')
plt.show()
```

4. `[Table]` In markup, make a $3\times3$ table that compares your training/testing accuracy for each experiment. 
  1. all features
  2. best $N$ features
  * Explain your results

# <img src="https://img.icons8.com/color/32/000000/speech-bubble-with-dots.png"/> **Student Response**

*Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum*

***
"""
