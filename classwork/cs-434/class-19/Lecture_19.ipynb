{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture 19.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7EpbisnFnXt",
        "colab_type": "text"
      },
      "source": [
        "# Lecture 19 - Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmuyKy5AFuU5",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "##### CS 434 - Data Mining and Machine Learning\n",
        "##### Oregon State University-Cascades\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k9b5hDwQSTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import gzip\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miCw6NGWR0wu",
        "colab_type": "text"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/color/32/000000/workflow.png\"/> Sequential data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3luanjbSGjD1",
        "colab_type": "text"
      },
      "source": [
        "For many machine learning algorithms, we assume that the input is independent and identically distributed (IID) data. This means that the training examples are *mutually independent* and have the same underlying distribution.\n",
        "\n",
        "This assumption is not valid when we deal with sequences. In this case order matters.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6we7sCV4GFsu",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/serial-tasks.png\"/> Representing sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buzncyTrSlKo",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_01.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKnMIJUVR0wx",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/categorize.png\"/>  Categories of sequence modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqegivXPSrsK",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_02.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAw68fATR0wz",
        "colab_type": "text"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/color/32/000000/vector.png\"/> RNNs for modeling sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiYC4x8tIV_q",
        "colab_type": "text"
      },
      "source": [
        "##<img src=\"https://img.icons8.com/color/32/000000/repeat.png\"/> Understanding the RNN looping mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvxZD1pkIfT0",
        "colab_type": "text"
      },
      "source": [
        "In the following, he input layer ($\\mathbf{x}$), hidden layer ($\\mathbf{h}$), and output layer ($\\mathbf{o}$) are vectors that contain many units."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-cYZZm2S2XI",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_03.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxkf0tS3S8pb",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_04.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQIudSvBR0w5",
        "colab_type": "text"
      },
      "source": [
        "##  <img src=\"https://img.icons8.com/color/32/000000/abacus.png\"/> Computing activations in an RNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ruBK8NJ_FW",
        "colab_type": "text"
      },
      "source": [
        "* $\\textbf{W}_{xh}$ :  weight matrix between the input $\\textbf{x}^t$ and the hidden layer $\\textbf{h}$\n",
        "* $\\textbf{W}_{hh}$ : weight matrix associated with the recurrent edge\n",
        "* $\\textbf{W}_{ho}$ : weight matrix between the hidden layer and output layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZrfkQMiTFQd",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_05.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cptnbIjvKx2f",
        "colab_type": "text"
      },
      "source": [
        "For the hidden layer the net input $\\textbf{z}_h$ (preactivation), is computed through a linear combination.  We compute the sum of multiplications of the weight matrices with the corresponding vectors and add the bias unit:\n",
        "\n",
        "$$\\textbf{z}_h^t = \\textbf{W}_{xh}\\textbf{x}^t + \\textbf{W}_{hh}\\textbf{h}^{t-1} + \\textbf{b}_h$$\n",
        "\n",
        "Then the activations of the hidden units at the time step $t$ are calculated as follows:\n",
        "\n",
        "$$\\textbf{h}^t = \\phi_h(\\textbf{z}^t_h) = \\phi_h(\\textbf{W}_{xh}\\textbf{x}^t + \\textbf{W}_{hh}\\textbf{h}^{t-1} + \\textbf{b}_h)$$\n",
        "\n",
        "or we can use the concatenated weight matrix, $\\textbf{W}_h = [ \\ \\textbf{W}_{xh}; \\textbf{W}_{hh} \\ ]$, which results in:\n",
        "\n",
        "$$\\textbf{h}^t = \\phi_h(\\textbf{z}^t_h) = \\phi_h( [ \\ \\textbf{W}_{xh}; \\textbf{W}_{hh} \\ ] \\begin{bmatrix}\n",
        "\\textbf{x}^t \\\\\n",
        "\\textbf{h}^{t-1}\n",
        "\\end{bmatrix}  + \\textbf{b}_h)$$\n",
        "\n",
        "where \n",
        "* $\\textbf{b}_h$ is the bias vector for the hidden units\n",
        "* $\\phi_h(\\cdot)$ is the activation function of the hidden layer\n",
        "\n",
        "Once the activations of the hidden units at the current time step are computed, then the activations of the output units will be computed, as follows:\n",
        "\n",
        "$$\\textbf{o}^t = \\phi_o(\\textbf{W}_{ho}\\textbf{h}^t + \\textbf{b}_o)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBJQpMVwU2XV",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_06.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHkAPngeR0w-",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/invisible.png\"/> Hidden-recurrence vs. output-recurrence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APKsxz4LS8x6",
        "colab_type": "text"
      },
      "source": [
        "The net activations from the output layer the previous time step $\\textbf{o}^{t-1}$ can be added in one of two ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrRTtCb8U83Q",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_07.png width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml53dqWfR0xA",
        "colab_type": "code",
        "outputId": "4d3b61ce-d1a8-4cca-b9f7-1edcbf5f6217",
        "colab": {}
      },
      "source": [
        "# create the layer and assign the weights\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "rnn_layer = tf.keras.layers.SimpleRNN(\n",
        "    units=2, use_bias=True, \n",
        "    return_sequences=True)\n",
        "rnn_layer.build(input_shape=(None, None, 5))\n",
        "\n",
        "w_xh, w_oo, b_h = rnn_layer.weights\n",
        "\n",
        "print('W_xh shape:', w_xh.shape)\n",
        "print('W_oo shape:', w_oo.shape)\n",
        "print('b_h shape:', b_h.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_xh shape: (5, 2)\n",
            "W_oo shape: (2, 2)\n",
            "b_h shape: (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfVd2BA_R0xC",
        "colab_type": "code",
        "outputId": "9c836686-58b1-4d82-b95e-5c545b7f5897",
        "colab": {}
      },
      "source": [
        "# create tensor\n",
        "x_seq = tf.convert_to_tensor(\n",
        "    [[1.0]*5, [2.0]*5, [3.0]*5],\n",
        "    dtype=tf.float32)\n",
        "\n",
        "## output of SimepleRNN:\n",
        "output = rnn_layer(tf.reshape(x_seq, shape=(1, 3, 5)))\n",
        "\n",
        "## manually computing the output:\n",
        "out_man = []\n",
        "for t in range(len(x_seq)):\n",
        "    xt = tf.reshape(x_seq[t], (1, 5))\n",
        "    print('Time step {} =>'.format(t))\n",
        "    print('   Input           :', xt.numpy())\n",
        "    \n",
        "    ht = tf.matmul(xt, w_xh) + b_h    \n",
        "    print('   Hidden          :', ht.numpy())\n",
        "    \n",
        "    if t>0:\n",
        "        prev_o = out_man[t-1]\n",
        "    else:\n",
        "        prev_o = tf.zeros(shape=(ht.shape))\n",
        "        \n",
        "    ot = ht + tf.matmul(prev_o, w_oo)\n",
        "    ot = tf.math.tanh(ot)\n",
        "    out_man.append(ot)\n",
        "    print('   Output (manual) :', ot.numpy())\n",
        "    print('   SimpleRNN output:'.format(t), output[0][t].numpy())\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time step 0 =>\n",
            "   Input           : [[1. 1. 1. 1. 1.]]\n",
            "   Hidden          : [[0.41464037 0.96012145]]\n",
            "   Output (manual) : [[0.39240566 0.74433106]]\n",
            "   SimpleRNN output: [0.39240566 0.74433106]\n",
            "\n",
            "Time step 1 =>\n",
            "   Input           : [[2. 2. 2. 2. 2.]]\n",
            "   Hidden          : [[0.82928073 1.9202429 ]]\n",
            "   Output (manual) : [[0.80116504 0.9912947 ]]\n",
            "   SimpleRNN output: [0.80116504 0.9912947 ]\n",
            "\n",
            "Time step 2 =>\n",
            "   Input           : [[3. 3. 3. 3. 3.]]\n",
            "   Hidden          : [[1.243921  2.8803642]]\n",
            "   Output (manual) : [[0.95468265 0.9993069 ]]\n",
            "   SimpleRNN output: [0.95468265 0.9993069 ]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOsbt3ATR0xE",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/hard-to-find.png\"/> Challenges of learning long-range interactions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgghOYDoULur",
        "colab_type": "text"
      },
      "source": [
        "Because of the multiplicative factor ${\\partial \\textbf{h}^t \\over {\\partial \\textbf{h}^k}}$, in computing the gradients of a loss functions, the so-called **vanishing** and **exploding** gradient problems arise. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "br5dk4nlVCzH",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_08.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgF8o0sTR0xG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## <img src=\"https://img.icons8.com/color/32/000000/micro-sd.png\"/> Long Short-Term Memory cells "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHhHVwIs9BEA",
        "colab_type": "code",
        "outputId": "e67582c6-7fe9-483b-942c-31e363124c5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "YouTubeVideo('8HyCNIVRbSU')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"400\"\n",
              "            height=\"300\"\n",
              "            src=\"https://www.youtube.com/embed/8HyCNIVRbSU\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.YouTubeVideo at 0x7f3d5f3801d0>"
            ],
            "image/jpeg": "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\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEeHGoXXyBjk",
        "colab_type": "text"
      },
      "source": [
        "LSTMs were introduced to overcome the vanishing gradient problem. The building block of an LSTM is a **memory cell** which replaces the hidden layer of a standard RNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fK9lY0KVIMW",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_09.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4l02oniV69S",
        "colab_type": "text"
      },
      "source": [
        "The **forget gate** $\\textbf{f}_t$ allows the memory cell to reset the cell state without growing indefinitely. In fact, the forget gate decides which information is allowed to go through and which information to suppress. \n",
        "\n",
        "$$\\textbf{f}_t = \\sigma(\\textbf{W}_{xf}\\textbf{x}^t + \\textbf{W}_{hf}\\textbf{h}^{t-1} + \\textbf{b}_f)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7LByI0PW4MD",
        "colab_type": "text"
      },
      "source": [
        "The **input gate** $\\textbf{i}_t$ and **candiate value** $\\widetilde {C}_t$ are responsible for updating the cell state. They are computed as follows:\n",
        "\n",
        "$$\\textbf{i}_t = \\sigma(\\textbf{W}_{xi}\\textbf{x}^t + \\textbf{W}_{hi}\\textbf{h}^{t-1} + \\textbf{b}_i)$$\n",
        "\n",
        "$$\\widetilde{C}_t = \\tanh(\\textbf{W}_{xc}\\textbf{x}^t + \\textbf{W}_{hc}\\textbf{h}^{t-1} + \\textbf{b}_c)$$\n",
        "\n",
        "The cell state at time $t$ is computed as follows:\n",
        "\n",
        "$$\\textbf{C}^t = (\\textbf{C}^{t-1} \\ \\odot \\ \\textbf{f}_t) \\ \\otimes \\ (\\textbf{i}_t \\ \\odot \\ \\widetilde{C}_j )$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFWklanuZAbh",
        "colab_type": "text"
      },
      "source": [
        "The **output gate** $\\textbf{o}_t$ decides how to update the values of the hidden units:\n",
        "\n",
        "$$\\textbf{o}_t = \\sigma(\\textbf{W}_{xo}\\textbf{x}^t + \\textbf{W}_{ho}\\textbf{h}^{t-1} + \\textbf{b}_o)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VJkRKogZg_8",
        "colab_type": "text"
      },
      "source": [
        "Given this, the hidden units at the current time step are computed as follows:\n",
        "\n",
        "$$\\textbf{h}^t = \\textbf{o}_t \\odot \\tanh(\\textbf{C}^t)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2L-ZiSpZgkc",
        "colab_type": "text"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/color/32/000000/new-document.png\"/> Implementing RNNs for sequence modeling in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBfKLu7MaWKF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## <img src=\"https://img.icons8.com/color/32/000000/imdb.png\"/> Project one: predicting the sentiment of IMDb movie reviews\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjyMf-_4yYlb",
        "colab_type": "text"
      },
      "source": [
        "**Sentiment** analysis is concerned with analyzing the expressed opinion of a sentence or text document. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9I45k4McAvF",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/database-restore.png\"/> Preparing the movie review data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KKnrPDgaWKH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open('../ch08/movie_data.csv.gz', 'rb') as f_in, open('movie_data.csv', 'wb') as f_out:\n",
        "    shutil.copyfileobj(f_in, f_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfI7Up_KaWKK",
        "colab_type": "code",
        "outputId": "bdbf6960-e9cd-48dd-b929-8c798673b9a5",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
        "\n",
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>49995</td>\n",
              "      <td>OK, lets start with the best. the building. al...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49996</td>\n",
              "      <td>The British 'heritage film' industry is out of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49997</td>\n",
              "      <td>I don't even know where to begin on this one. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49998</td>\n",
              "      <td>Richard Tyler is a little boy who is scared of...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49999</td>\n",
              "      <td>I waited long to watch this movie. Also becaus...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  sentiment\n",
              "49995  OK, lets start with the best. the building. al...          0\n",
              "49996  The British 'heritage film' industry is out of...          0\n",
              "49997  I don't even know where to begin on this one. ...          0\n",
              "49998  Richard Tyler is a little boy who is scared of...          0\n",
              "49999  I waited long to watch this movie. Also becaus...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpmN-56Oywef",
        "colab_type": "text"
      },
      "source": [
        "#### <img src=\"https://img.icons8.com/color/32/000000/stairs.png\"/> Pre-processing steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ablW976qy1DF",
        "colab_type": "text"
      },
      "source": [
        "**Step 1**. Create a TensorFlow dataset object and split it into separate training, testing, and validation partitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wAdKlmEaWKM",
        "colab_type": "code",
        "outputId": "bad4e0d4-bffc-47a2-e77f-87b4d8f3ded9",
        "colab": {}
      },
      "source": [
        "# Step 1: Create a dataset\n",
        "\n",
        "target = df.pop('sentiment')\n",
        "\n",
        "ds_raw = tf.data.Dataset.from_tensor_slices(\n",
        "    (df.values, target.values))\n",
        "\n",
        "## inspection:\n",
        "for ex in ds_raw.take(3):\n",
        "    tf.print(ex[0].numpy()[0][:50], ex[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
            "b'OK... so... I really like Kris Kristofferson and h' 0\n",
            "b'***SPOILER*** Do not read this, if you think about' 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3V8CLqFaWKO",
        "colab_type": "text"
      },
      "source": [
        " * **Train/validation/test splits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtu2n-SbaWKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split to train/test/validation\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "ds_raw = ds_raw.shuffle(\n",
        "    50000, reshuffle_each_iteration=False)\n",
        "\n",
        "ds_raw_test = ds_raw.take(25000)\n",
        "ds_raw_train_valid = ds_raw.skip(25000)\n",
        "ds_raw_train = ds_raw_train_valid.take(20000)\n",
        "ds_raw_valid = ds_raw_train_valid.skip(20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1TjXdie0HoF",
        "colab_type": "text"
      },
      "source": [
        "**Step 2.** Identify the unique words in the training dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMz0B1TCaWKQ",
        "colab_type": "text"
      },
      "source": [
        " * **Tokenizer and Encoder**\n",
        "   * `tfds.features.text.Tokenizer`: https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/Tokenizer\n",
        "   * `tfds.features.text.TokenTextEncoder`: https://www.tensorflow.org/datasets/api_docs/python/tfds/features/text/TokenTextEncoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPmUw9LqaWKQ",
        "colab_type": "code",
        "outputId": "550a6922-ba60-447b-c42b-443d332230cf",
        "colab": {}
      },
      "source": [
        "## Step 2: find unique tokens (words)\n",
        "tokenizer = tfds.features.text.Tokenizer()\n",
        "token_counts = Counter()\n",
        "\n",
        "for example in ds_raw_train:\n",
        "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        "    token_counts.update(tokens)\n",
        "    \n",
        "print('Vocab-size:', len(token_counts))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab-size: 87007\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvLYHaso0wsg",
        "colab_type": "text"
      },
      "source": [
        "**Step 3.** Map each unique word to a unique integer and encode the review text into encoded integers (an index of each unique word)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1-r1tHyaWKS",
        "colab_type": "code",
        "outputId": "af0108e7-ef2a-4a29-96ba-c4df2ab08481",
        "colab": {}
      },
      "source": [
        "## Step 3: encoding each unique token into integers\n",
        "\n",
        "encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
        "\n",
        "example_str = 'This is an example!'\n",
        "encoder.encode(example_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[232, 9, 270, 1123]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2yVK67naWKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Step 3-A: define the function for transformation\n",
        "\n",
        "def encode(text_tensor, label):\n",
        "    text = text_tensor.numpy()[0]\n",
        "    encoded_text = encoder.encode(text)\n",
        "    return encoded_text, label\n",
        "\n",
        "## Step 3-B: wrap the encode function to a TF Op.\n",
        "def encode_map_fn(text, label):\n",
        "    return tf.py_function(encode, inp=[text, label], \n",
        "                          Tout=(tf.int64, tf.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXQQ9Yk6aWKV",
        "colab_type": "code",
        "outputId": "1064bce5-dc7d-4180-e74d-905ef2dcca52",
        "colab": {}
      },
      "source": [
        "# encode text\n",
        "ds_train = ds_raw_train.map(encode_map_fn)\n",
        "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "ds_test = ds_raw_test.map(encode_map_fn)\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "for example in ds_train.shuffle(1000).take(5):\n",
        "    print('Sequence length:', example[0].shape)\n",
        "    \n",
        "example"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence length: (24,)\n",
            "Sequence length: (179,)\n",
            "Sequence length: (262,)\n",
            "Sequence length: (535,)\n",
            "Sequence length: (130,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: id=43302, shape=(130,), dtype=int64, numpy=\n",
              " array([  579,  1296,    32,   425,    40,   763,  9267,    65,   280,\n",
              "          308,     6,   481,   155,   473,     2,     3,   684,     9,\n",
              "          781,   176,   959,   730,  3917,    67,  9905,    13,   277,\n",
              "           24,    35,   371, 16368,     6,    14, 17231,    29,   187,\n",
              "         1651,   489,   503,   480,   143,    32,   270,  5851,  2402,\n",
              "           13,  3592,  3443,   425,  3313,   256,   257,  1577,   117,\n",
              "            8,   698,   270,   564,    56,     8,    42,  7517,  2629,\n",
              "          820,    25,    60,    79,   343,    32,   645,    14,   528,\n",
              "          241,    32,  1980,     8,    56,     8,    42,  1364,   573,\n",
              "         5183,    43,    12,  3870,    32,   312,   642,   251,  1401,\n",
              "        17232,     8,   698,   257,   750,     2,     9,    76,   235,\n",
              "            8,    42,   235,   840,   666,   258, 17233,   419,    32,\n",
              "        17234,   585,   420,   840,    25,    40,    13,    14,   198,\n",
              "          266,   623,   173,   179,  4103,   216,    25,   616, 14185,\n",
              "          186,    35, 16250,   120])>,\n",
              " <tf.Tensor: id=43303, shape=(), dtype=int64, numpy=0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81JdUC8MaWKW",
        "colab_type": "text"
      },
      "source": [
        "> Note: **batch() vs. padded_batch()**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0rCQtelaWKX",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "# this will result in error\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_data = all_encoded_data.batch(BATCH_SIZE)\n",
        "\n",
        "next(iter(train_data))\n",
        "\n",
        "# Running this will result in error\n",
        "# We cannot apply .batch() to this dataset\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUUCN4XfaWKX",
        "colab_type": "code",
        "outputId": "78471aa8-3a9d-4dcd-b648-354543e05ec5",
        "colab": {}
      },
      "source": [
        "## Take a small subset\n",
        "\n",
        "ds_subset = ds_train.take(8)\n",
        "for example in ds_subset:\n",
        "    print('Individual size:', example[0].shape)\n",
        "\n",
        "## batching the datasets\n",
        "ds_batched = ds_subset.padded_batch(\n",
        "    4, padded_shapes=([-1], []))\n",
        "\n",
        "for batch in ds_batched:\n",
        "    print('Batch dimension:', batch[0].shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Individual Shape: (119,)\n",
            "Individual Shape: (688,)\n",
            "Individual Shape: (308,)\n",
            "Individual Shape: (204,)\n",
            "Individual Shape: (326,)\n",
            "Individual Shape: (240,)\n",
            "Individual Shape: (127,)\n",
            "Individual Shape: (453,)\n",
            "Batch Shape: (4, 688)\n",
            "Batch Shape: (4, 453)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAOGyAIxaWKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## batching the datasets\n",
        "train_data = ds_train.padded_batch(\n",
        "    32, padded_shapes=([-1],[]))\n",
        "\n",
        "valid_data = ds_valid.padded_batch(\n",
        "    32, padded_shapes=([-1],[]))\n",
        "\n",
        "test_data = ds_test.padded_batch(\n",
        "    32, padded_shapes=([-1],[]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu0mGTmkaWKc",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/layers.png\"/> Embedding layers for sentence encoding\n",
        "\n",
        "\n",
        " * `input_dim`: number of words, i.e. maximum integer index + 1.\n",
        " * `output_dim`: \n",
        " * `input_length`: the length of (padded) sequence\n",
        "    * for example, `'This is an example' -> [0, 0, 0, 0, 0, 0, 3, 1, 8, 9]`   \n",
        "    => input_length is 10\n",
        " \n",
        " \n",
        "\n",
        " * When calling the layer, takes integer values as input,   \n",
        " the embedding layer convert each integer into float vector of size `[output_dim]`\n",
        "   * If input shape is `[BATCH_SIZE]`, output shape will be `[BATCH_SIZE, output_dim]`\n",
        "   * If input shape is `[BATCH_SIZE, 10]`, output shape will be `[BATCH_SIZE, 10, output_dim]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtoc-3IYcqSj",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_10.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuTskB9paWKQ",
        "colab_type": "text"
      },
      "source": [
        "**Encoding sequences:** keeping the last 100 items in each sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLzdCa7taWKe",
        "colab_type": "code",
        "outputId": "75363bdc-55ea-44eb-f08c-acd11c9f51e1",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=100,\n",
        "                    output_dim=6,\n",
        "                    input_length=20,\n",
        "                    name='embed-layer'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed-layer (Embedding)      (None, 20, 6)             600       \n",
            "=================================================================\n",
            "Total params: 600\n",
            "Trainable params: 600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnlNsCYxaWKf",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/wrench.png\"/> Building an RNN model\n",
        "\n",
        "* **Keras RNN layers:**\n",
        "  * `tf.keras.layers.SimpleRNN(units, return_sequences=False)`\n",
        "  * `tf.keras.layers.LSTM(..)`\n",
        "  * `tf.keras.layers.GRU(..)`\n",
        "  * `tf.keras.layers.Bidirectional()`\n",
        " \n",
        "* **Determine `return_sequenes=?`**\n",
        "  * In a multi-layer RNN, all RNN layers except the last one should have `return_sequenes=True`\n",
        "  * For the last RNN layer, decide based on the type of problem: \n",
        "     * many-to-many: -> `return_sequences=True`\n",
        "     * many-to-one : -> `return_sequenes=False`\n",
        "     * ..\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpLcb7TIaWKf",
        "colab_type": "code",
        "outputId": "82466cde-8798-4d61-a0a3-735e34cef026",
        "colab": {}
      },
      "source": [
        "## An example of building a RNN model\n",
        "## with SimpleRNN layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 32)          32000     \n",
            "_________________________________________________________________\n",
            "simple_rnn_1 (SimpleRNN)     (None, None, 32)          2080      \n",
            "_________________________________________________________________\n",
            "simple_rnn_2 (SimpleRNN)     (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 36,193\n",
            "Trainable params: 36,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9uMQS01aWKi",
        "colab_type": "code",
        "outputId": "083ebb3e-c0a8-4734-b8ba-ae52d4fa4622",
        "colab": {}
      },
      "source": [
        "## An example of building a RNN model\n",
        "## with LSTM layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(LSTM(32, return_sequences=True))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 32)          8320      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 336,673\n",
            "Trainable params: 336,673\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIkdUmjQaWKk",
        "colab_type": "code",
        "outputId": "f7d99b4e-d627-4dea-f231-1e352327be74",
        "colab": {}
      },
      "source": [
        "## An example of building a RNN model\n",
        "## with GRU layer\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 32))\n",
        "model.add(GRU(32, return_sequences=True))\n",
        "model.add(GRU(32))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 32)          6336      \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 32)                6336      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 332,705\n",
            "Trainable params: 332,705\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLr3BOX-aWKn",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/bipolar-disease.png\"/>  Building an RNN model for the sentiment analysis task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqPNs8EnaWKn",
        "colab_type": "code",
        "outputId": "113af546-16f7-4f9c-b07f-1a2bf44420e9",
        "colab": {}
      },
      "source": [
        "embedding_dim = 20\n",
        "vocab_size = len(token_counts) + 2\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "## build the model\n",
        "bi_lstm_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        name='embed-layer'),\n",
        "    \n",
        "    tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(64, name='lstm-layer'),\n",
        "        name='bidir-lstm'), \n",
        "\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "bi_lstm_model.summary()\n",
        "\n",
        "## compile and train:\n",
        "bi_lstm_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history = bi_lstm_model.fit(\n",
        "    train_data, \n",
        "    validation_data=valid_data, \n",
        "    epochs=10)\n",
        "\n",
        "## evaluate on the test data\n",
        "test_results= bi_lstm_model.evaluate(test_data)\n",
        "print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed-layer (Embedding)      (None, None, 20)          1740180   \n",
            "_________________________________________________________________\n",
            "bidir-lstm (Bidirectional)   (None, 128)               43520     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,792,021\n",
            "Trainable params: 1,792,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 383s 613ms/step - loss: 0.5173 - accuracy: 0.7376 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 369s 590ms/step - loss: 0.2747 - accuracy: 0.8955 - val_loss: 0.3982 - val_accuracy: 0.8516\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 369s 590ms/step - loss: 0.1528 - accuracy: 0.9478 - val_loss: 0.4270 - val_accuracy: 0.8588\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 369s 590ms/step - loss: 0.0958 - accuracy: 0.9674 - val_loss: 0.6082 - val_accuracy: 0.8358\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 368s 589ms/step - loss: 0.0551 - accuracy: 0.9836 - val_loss: 0.6766 - val_accuracy: 0.8468\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 368s 590ms/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 0.6429 - val_accuracy: 0.8398\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 369s 591ms/step - loss: 0.0418 - accuracy: 0.9870 - val_loss: 0.6093 - val_accuracy: 0.8388\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 369s 590ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.7021 - val_accuracy: 0.8356\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 368s 590ms/step - loss: 0.0308 - accuracy: 0.9909 - val_loss: 0.7601 - val_accuracy: 0.8392\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 369s 590ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.8158 - val_accuracy: 0.8388\n",
            "782/782 [==============================] - 144s 185ms/step - loss: 0.8131 - accuracy: 0.8392\n",
            "Test Acc.: 83.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-e7NV4eaWKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('models'):\n",
        "    os.mkdir('models')\n",
        "\n",
        "bi_lstm_model.save('models/Bidir-LSTM-full-length-seq.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdus3m2haWKr",
        "colab_type": "text"
      },
      "source": [
        "Try **SimpleRNN** with short sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3GchyHXaWKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to preprocess all data\n",
        "def preprocess_datasets(\n",
        "    ds_raw_train, \n",
        "    ds_raw_valid, \n",
        "    ds_raw_test,\n",
        "    max_seq_length=None,\n",
        "    batch_size=32):\n",
        "    \n",
        "    ## Step 1: (already done => creating a dataset)\n",
        "    ## Step 2: find unique tokens\n",
        "    tokenizer = tfds.features.text.Tokenizer()\n",
        "    token_counts = Counter()\n",
        "\n",
        "    for example in ds_raw_train:\n",
        "        tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        "        if max_seq_length is not None:\n",
        "            tokens = tokens[-max_seq_length:]\n",
        "        token_counts.update(tokens)\n",
        "\n",
        "    print('Vocab-size:', len(token_counts))\n",
        "\n",
        "\n",
        "    ## Step 3: encoding the texts\n",
        "    encoder = tfds.features.text.TokenTextEncoder(token_counts)\n",
        "    def encode(text_tensor, label):\n",
        "        text = text_tensor.numpy()[0]\n",
        "        encoded_text = encoder.encode(text)\n",
        "        if max_seq_length is not None:\n",
        "            encoded_text = encoded_text[-max_seq_length:]\n",
        "        return encoded_text, label\n",
        "\n",
        "    def encode_map_fn(text, label):\n",
        "        return tf.py_function(encode, inp=[text, label], \n",
        "                              Tout=(tf.int64, tf.int64))\n",
        "\n",
        "    ds_train = ds_raw_train.map(encode_map_fn)\n",
        "    ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "    ds_test = ds_raw_test.map(encode_map_fn)\n",
        "\n",
        "    ## Step 4: batching the datasets\n",
        "    train_data = ds_train.padded_batch(\n",
        "        batch_size, padded_shapes=([-1],[]))\n",
        "\n",
        "    valid_data = ds_valid.padded_batch(\n",
        "        batch_size, padded_shapes=([-1],[]))\n",
        "\n",
        "    test_data = ds_test.padded_batch(\n",
        "        batch_size, padded_shapes=([-1],[]))\n",
        "\n",
        "    return (train_data, valid_data, \n",
        "            test_data, len(token_counts))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NczBupDaWKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build RNN model\n",
        "def build_rnn_model(embedding_dim, vocab_size,\n",
        "                    recurrent_type='SimpleRNN',\n",
        "                    n_recurrent_units=64,\n",
        "                    n_recurrent_layers=1,\n",
        "                    bidirectional=True):\n",
        "\n",
        "    tf.random.set_seed(1)\n",
        "\n",
        "    # build the model\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    model.add(\n",
        "        Embedding(\n",
        "            input_dim=vocab_size,\n",
        "            output_dim=embedding_dim,\n",
        "            name='embed-layer')\n",
        "    )\n",
        "    \n",
        "    for i in range(n_recurrent_layers):\n",
        "        return_sequences = (i < n_recurrent_layers-1)\n",
        "            \n",
        "        if recurrent_type == 'SimpleRNN':\n",
        "            recurrent_layer = SimpleRNN(\n",
        "                units=n_recurrent_units, \n",
        "                return_sequences=return_sequences,\n",
        "                name='simprnn-layer-{}'.format(i))\n",
        "        elif recurrent_type == 'LSTM':\n",
        "            recurrent_layer = LSTM(\n",
        "                units=n_recurrent_units, \n",
        "                return_sequences=return_sequences,\n",
        "                name='lstm-layer-{}'.format(i))\n",
        "        elif recurrent_type == 'GRU':\n",
        "            recurrent_layer = GRU(\n",
        "                units=n_recurrent_units, \n",
        "                return_sequences=return_sequences,\n",
        "                name='gru-layer-{}'.format(i))\n",
        "        \n",
        "        if bidirectional:\n",
        "            recurrent_layer = Bidirectional(\n",
        "                recurrent_layer, name='bidir-'+recurrent_layer.name)\n",
        "            \n",
        "        model.add(recurrent_layer)\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    \n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr6TxJHDaWKu",
        "colab_type": "code",
        "outputId": "3dbc0d5b-9e1f-4fdc-b60d-72437b53a061",
        "colab": {}
      },
      "source": [
        "# run simple RNN\n",
        "batch_size = 32\n",
        "embedding_dim = 20\n",
        "max_seq_length = 100\n",
        "\n",
        "train_data, valid_data, test_data, n = preprocess_datasets(\n",
        "    ds_raw_train, ds_raw_valid, ds_raw_test, \n",
        "    max_seq_length=max_seq_length, \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "vocab_size = n + 2\n",
        "\n",
        "rnn_model = build_rnn_model(\n",
        "    embedding_dim, vocab_size,\n",
        "    recurrent_type='SimpleRNN', \n",
        "    n_recurrent_units=64,\n",
        "    n_recurrent_layers=1,\n",
        "    bidirectional=True)\n",
        "\n",
        "rnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab-size: 58063\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed-layer (Embedding)      (None, None, 20)          1161300   \n",
            "_________________________________________________________________\n",
            "bidir-simprnn-layer-0 (Bidir (None, 128)               10880     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,180,501\n",
            "Trainable params: 1,180,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BiqS8ytaWKw",
        "colab_type": "code",
        "outputId": "1b9344d7-07a5-4b54-e972-d36b5a3f95f4",
        "colab": {}
      },
      "source": [
        "# compile and run model\n",
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history = rnn_model.fit(\n",
        "    train_data, \n",
        "    validation_data=valid_data, \n",
        "    epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 68s 109ms/step - loss: 0.7055 - accuracy: 0.5026 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.7037 - accuracy: 0.5113 - val_loss: 0.6953 - val_accuracy: 0.5072\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.6954 - accuracy: 0.5213 - val_loss: 0.6884 - val_accuracy: 0.5452\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 67s 106ms/step - loss: 0.6317 - accuracy: 0.6259 - val_loss: 0.6152 - val_accuracy: 0.6522\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.4913 - accuracy: 0.7629 - val_loss: 0.7798 - val_accuracy: 0.6278\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.4252 - accuracy: 0.8094 - val_loss: 0.6105 - val_accuracy: 0.7432\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.4100 - accuracy: 0.8122 - val_loss: 0.6718 - val_accuracy: 0.7016\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.3749 - accuracy: 0.8281 - val_loss: 0.7762 - val_accuracy: 0.6348\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.2711 - accuracy: 0.8813 - val_loss: 0.7503 - val_accuracy: 0.6892\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 66s 106ms/step - loss: 0.1665 - accuracy: 0.9367 - val_loss: 0.7172 - val_accuracy: 0.7454\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK3C_HLKaWKx",
        "colab_type": "code",
        "outputId": "1d0fc571-f394-429b-e2af-bf813550450c",
        "colab": {}
      },
      "source": [
        "# evalute on test set\n",
        "results = rnn_model.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 39s 50ms/step - loss: 0.7098 - accuracy: 0.7478\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyQkg_KCaWKz",
        "colab_type": "code",
        "outputId": "d7f2cb1c-6081-49a9-dd30-761919a24f6b",
        "colab": {}
      },
      "source": [
        "# view accuracy\n",
        "print('Test Acc.: {:.2f}%'.format(results[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc.: 74.78%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Uwj5rCUaWK0",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/circled-dot.png\"/> Optional: Uni-directional SimpleRNN with full-length sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3GaARXqaWK1",
        "colab_type": "code",
        "outputId": "14e44f5e-3bbd-4d61-d4f0-8e989913f29a",
        "colab": {}
      },
      "source": [
        "# no sequence length\n",
        "batch_size = 32\n",
        "embedding_dim = 20\n",
        "max_seq_length = None\n",
        "\n",
        "train_data, valid_data, test_data, n = preprocess_datasets(\n",
        "    ds_raw_train, ds_raw_valid, ds_raw_test, \n",
        "    max_seq_length=max_seq_length, \n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "\n",
        "vocab_size = n + 2\n",
        "\n",
        "rnn_model = build_rnn_model(\n",
        "    embedding_dim, vocab_size,\n",
        "    recurrent_type='SimpleRNN', \n",
        "    n_recurrent_units=64,\n",
        "    n_recurrent_layers=1,\n",
        "    bidirectional=False)\n",
        "\n",
        "rnn_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab-size: 87007\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embed-layer (Embedding)      (None, None, 20)          1740180   \n",
            "_________________________________________________________________\n",
            "simprnn-layer-0 (SimpleRNN)  (None, 64)                5440      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,749,845\n",
            "Trainable params: 1,749,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgKVHojDaWK2",
        "colab_type": "code",
        "outputId": "45dbf22c-5594-418a-d08e-d38f3629027e",
        "colab": {}
      },
      "source": [
        "# compile and run model\n",
        "rnn_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "history = rnn_model.fit(\n",
        "    train_data, \n",
        "    validation_data=valid_data, \n",
        "    epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 225s 361ms/step - loss: 0.6993 - accuracy: 0.5034 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 225s 361ms/step - loss: 0.6993 - accuracy: 0.5006 - val_loss: 0.6998 - val_accuracy: 0.5010\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 226s 361ms/step - loss: 0.6968 - accuracy: 0.5034 - val_loss: 0.6960 - val_accuracy: 0.5004\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 225s 360ms/step - loss: 0.6958 - accuracy: 0.5038 - val_loss: 0.6953 - val_accuracy: 0.5002\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 226s 361ms/step - loss: 0.6952 - accuracy: 0.5045 - val_loss: 0.6947 - val_accuracy: 0.4952\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 226s 361ms/step - loss: 0.6945 - accuracy: 0.5080 - val_loss: 0.6945 - val_accuracy: 0.4956\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 225s 360ms/step - loss: 0.6940 - accuracy: 0.5109 - val_loss: 0.6945 - val_accuracy: 0.4960\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 225s 360ms/step - loss: 0.6936 - accuracy: 0.5110 - val_loss: 0.6963 - val_accuracy: 0.4968\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 226s 361ms/step - loss: 0.6934 - accuracy: 0.5101 - val_loss: 0.6948 - val_accuracy: 0.4960\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 225s 361ms/step - loss: 0.6935 - accuracy: 0.5096 - val_loss: 0.6936 - val_accuracy: 0.4986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q1ZD06rSIW2",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/subtitles.png\"/> Project two: character-level language modeling in TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCEQWlgW9cam",
        "colab_type": "text"
      },
      "source": [
        "In this model, the data is a text document and our goal is to develop a model that generates new text that is similar in style to the input document. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aJ-i3Y4VLtw",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_11.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tE5HxjNSIW5",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/book.png\"/> Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPcDFHx49p62",
        "colab_type": "text"
      },
      "source": [
        "Data: [The Mysterious Island](http://www.gutenberg.org/files/1268/1268-0.txt) by Jules Verne (1874)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99Z3VJ0KSIW6",
        "colab_type": "code",
        "outputId": "b2205f7a-a243-4ee1-98cd-c3ed54c7123a",
        "colab": {}
      },
      "source": [
        "! curl -O http://www.gutenberg.org/files/1268/1268-0.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1144k  100 1144k    0     0  1807k      0 --:--:-- --:--:-- --:--:-- 1807k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLSwEnRFSIW-",
        "colab_type": "code",
        "outputId": "49db65dc-86a0-449c-bb1d-f64a69480880",
        "colab": {}
      },
      "source": [
        "## Reading and processing text\n",
        "with open('1268-0.txt', 'r') as fp:\n",
        "    text=fp.read()\n",
        "    \n",
        "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
        "end_indx = text.find('End of the Project Gutenberg')\n",
        "print(start_indx, end_indx)\n",
        "\n",
        "text = text[start_indx:end_indx]\n",
        "char_set = set(text)\n",
        "print('Total Length:', len(text))\n",
        "print('Unique Characters:', len(char_set))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "567 1112917\n",
            "Total Length: 1112350\n",
            "Unique Characters: 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEoK1qFTVaVB",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_12.png width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBMZwvYMSIXH",
        "colab_type": "code",
        "outputId": "769fc8a1-d026-414f-9416-832dd0639022",
        "colab": {}
      },
      "source": [
        "# character to integer map\n",
        "chars_sorted = sorted(char_set)\n",
        "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
        "char_array = np.array(chars_sorted)\n",
        "\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32)\n",
        "\n",
        "print('Text encoded shape: ', text_encoded.shape)\n",
        "\n",
        "print(text[:15], '     == Encoding ==> ', text_encoded[:15])\n",
        "print(text_encoded[15:21], ' == Reverse  ==> ', ''.join(char_array[text_encoded[15:21]]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text encoded shape:  (1112350,)\n",
            "THE MYSTERIOUS       == Encoding ==>  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
            "[33 43 36 25 38 28]  == Reverse  ==>  ISLAND\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0QcpNSeVePP",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_13.png width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFHGwpuEaXsq",
        "colab_type": "code",
        "outputId": "e8732dde-a145-4bd4-adee-6e2e0088f2c2",
        "colab": {}
      },
      "source": [
        "# encode dataset\n",
        "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
        "\n",
        "for ex in ds_text_encoded.take(5):\n",
        "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44 -> T\n",
            "32 -> H\n",
            "29 -> E\n",
            "1 ->  \n",
            "37 -> M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuDrVmNISIXP",
        "colab_type": "code",
        "outputId": "55f51d34-825b-492f-b10f-1901cea3324d",
        "colab": {}
      },
      "source": [
        "# clip sequence length to 40\n",
        "seq_length = 40\n",
        "chunk_size = seq_length + 1\n",
        "\n",
        "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
        "\n",
        "## inspection:\n",
        "for seq in ds_chunks.take(1):\n",
        "    input_seq = seq[:seq_length].numpy()\n",
        "    target = seq[seq_length].numpy()\n",
        "    print(input_seq, ' -> ', target)\n",
        "    print(repr(''.join(char_array[input_seq])), \n",
        "          ' -> ', repr(''.join(char_array[target])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[44 32 29  1 37 48 43 44 29 42 33 39 45 43  1 33 43 36 25 38 28  1  6  6\n",
            "  6  0  0  0  0  0 40 67 64 53 70 52 54 53  1 51]  ->  74\n",
            "'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'  ->  'y'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6xhxGfWVpIx",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_14.png width=\"800\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hzQ4VdaSIXU",
        "colab_type": "code",
        "outputId": "a16b4380-69ad-4f1b-c30e-bc3e9d14a558",
        "colab": {}
      },
      "source": [
        "## define the function for splitting x & y\n",
        "def split_input_target(chunk):\n",
        "    input_seq = chunk[:-1]\n",
        "    target_seq = chunk[1:]\n",
        "    return input_seq, target_seq\n",
        "\n",
        "ds_sequences = ds_chunks.map(split_input_target)\n",
        "\n",
        "## inspection:\n",
        "for example in ds_sequences.take(2):\n",
        "    print(' Input (x):', repr(''.join(char_array[example[0].numpy()])))\n",
        "    print('Target (y):', repr(''.join(char_array[example[1].numpy()])))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Input (x): 'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
            "Target (y): 'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
            "\n",
            " Input (x): ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
            "Target (y): 'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hFKVCecSIXX",
        "colab_type": "code",
        "outputId": "05c40c2e-8e4f-4e38-9d0c-4a779a11792e",
        "colab": {}
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)# drop_remainder=True)\n",
        "\n",
        "ds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 40), (None, 40)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOjTSc2GSIXZ",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/maintenance.png\"/>Building a character-level RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftYzmj2_SIXa",
        "colab_type": "code",
        "outputId": "16cd1c56-ed56-4e0a-cf24-40422170ef81",
        "colab": {}
      },
      "source": [
        "# build model\n",
        "def build_model(vocab_size, embedding_dim, rnn_units):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "        tf.keras.layers.LSTM(\n",
        "            rnn_units, return_sequences=True),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "charset_size = len(char_array)\n",
        "embedding_dim = 256\n",
        "rnn_units = 512\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size = charset_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 256)         20480     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, None, 512)         1574912   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 80)          41040     \n",
            "=================================================================\n",
            "Total params: 1,636,432\n",
            "Trainable params: 1,636,432\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eezQMREZSIXc",
        "colab_type": "code",
        "outputId": "25368482-51e4-4063-b3bc-d8ef9e547c80",
        "colab": {}
      },
      "source": [
        "# compile and train model\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True\n",
        "    ))\n",
        "\n",
        "model.fit(ds, epochs=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "424/424 [==============================] - 94s 221ms/step - loss: 2.3011\n",
            "Epoch 2/20\n",
            "424/424 [==============================] - 93s 219ms/step - loss: 1.7332\n",
            "Epoch 3/20\n",
            "424/424 [==============================] - 93s 218ms/step - loss: 1.5343\n",
            "Epoch 4/20\n",
            "424/424 [==============================] - 93s 219ms/step - loss: 1.4204\n",
            "Epoch 5/20\n",
            "424/424 [==============================] - 93s 220ms/step - loss: 1.3477\n",
            "Epoch 6/20\n",
            "424/424 [==============================] - 93s 221ms/step - loss: 1.2976\n",
            "Epoch 7/20\n",
            "424/424 [==============================] - 93s 220ms/step - loss: 1.2597\n",
            "Epoch 8/20\n",
            "424/424 [==============================] - 93s 219ms/step - loss: 1.2286\n",
            "Epoch 9/20\n",
            "424/424 [==============================] - 92s 218ms/step - loss: 1.2030\n",
            "Epoch 10/20\n",
            "424/424 [==============================] - 93s 220ms/step - loss: 1.1817\n",
            "Epoch 11/20\n",
            "424/424 [==============================] - 94s 221ms/step - loss: 1.1618\n",
            "Epoch 12/20\n",
            "424/424 [==============================] - 94s 221ms/step - loss: 1.1446\n",
            "Epoch 13/20\n",
            "424/424 [==============================] - 94s 221ms/step - loss: 1.1283\n",
            "Epoch 14/20\n",
            "424/424 [==============================] - 93s 218ms/step - loss: 1.1126\n",
            "Epoch 15/20\n",
            "424/424 [==============================] - 93s 220ms/step - loss: 1.0985\n",
            "Epoch 16/20\n",
            "424/424 [==============================] - 92s 218ms/step - loss: 1.0845\n",
            "Epoch 17/20\n",
            "424/424 [==============================] - 93s 220ms/step - loss: 1.0718\n",
            "Epoch 18/20\n",
            "424/424 [==============================] - 94s 222ms/step - loss: 1.0589\n",
            "Epoch 19/20\n",
            "424/424 [==============================] - 93s 219ms/step - loss: 1.0458\n",
            "Epoch 20/20\n",
            "424/424 [==============================] - 94s 221ms/step - loss: 1.0337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd30df77950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MD3OtBSIXf",
        "colab_type": "text"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/32/000000/new-by-copy.png\"/> Evaluation phase: generating new text passages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GcUrZB0SIXf",
        "colab_type": "code",
        "outputId": "023fd122-8616-4a22-f7ba-af6df52b2428",
        "colab": {}
      },
      "source": [
        "# generate random samples\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 1.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probabilities: [0.33333334 0.33333334 0.33333334]\n",
            "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4Q1bE1PSIXi",
        "colab_type": "code",
        "outputId": "a35c3efd-b105-4659-eff3-14e94e34f1c3",
        "colab": {}
      },
      "source": [
        "# adjust logits\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "logits = [[1.0, 1.0, 3.0]]\n",
        "print('Probabilities:', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "samples = tf.random.categorical(\n",
        "    logits=logits, num_samples=10)\n",
        "tf.print(samples.numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probabilities: [0.10650698 0.10650698 0.78698605]\n",
            "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc6DTRF-SIXk",
        "colab_type": "code",
        "outputId": "d4a38a83-bcc4-45c7-c9d1-a43fb90393d1",
        "colab": {}
      },
      "source": [
        "# function to sample \n",
        "def sample(model, starting_str, \n",
        "           len_generated_text=500, \n",
        "           max_input_length=40,\n",
        "           scale_factor=1.0):\n",
        "    encoded_input = [char2int[s] for s in starting_str]\n",
        "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
        "\n",
        "    generated_str = starting_str\n",
        "\n",
        "    model.reset_states()\n",
        "    for i in range(len_generated_text):\n",
        "        logits = model(encoded_input)\n",
        "        logits = tf.squeeze(logits, 0)\n",
        "\n",
        "        scaled_logits = logits * scale_factor\n",
        "        new_char_indx = tf.random.categorical(\n",
        "            scaled_logits, num_samples=1)\n",
        "        \n",
        "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()    \n",
        "\n",
        "        generated_str += str(char_array[new_char_indx])\n",
        "        \n",
        "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
        "        encoded_input = tf.concat(\n",
        "            [encoded_input, new_char_indx],\n",
        "            axis=1)\n",
        "        encoded_input = encoded_input[:, -max_input_length:]\n",
        "\n",
        "    return generated_str\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='The island'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The island is open he heard the victory of the\n",
            "Mercy, and brought it into them, and they no longer continue, some on the little man of the felting circle of slopes.\n",
            "\n",
            "The engineer troused, he could not find our companions.\n",
            "\n",
            "\n",
            "\n",
            "Chapter 11\n",
            "\n",
            "At this position, he might just as if his first true to be finished, and he\n",
            "though not more I can this teles.\n",
            "\n",
            "Why shall fear line, answered the reporter, what a disposal silence was advanced with them, and in masterspon.\n",
            "\n",
            "Before three heights of the\n",
            "Frenchant Heights \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zsew0-GeSIXn",
        "colab_type": "text"
      },
      "source": [
        "* **Predictability vs. randomness**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfx7If54SIXn",
        "colab_type": "code",
        "outputId": "c56baeb7-a0f3-44c8-cc17-4aadcc3e09ab",
        "colab": {}
      },
      "source": [
        "# controlling predictability\n",
        "logits = np.array([[1.0, 1.0, 3.0]])\n",
        "\n",
        "print('Probabilities before scaling:        ', tf.math.softmax(logits).numpy()[0])\n",
        "\n",
        "print('Probabilities after scaling with 0.5:', tf.math.softmax(0.5*logits).numpy()[0])\n",
        "\n",
        "print('Probabilities after scaling with 0.1:', tf.math.softmax(0.1*logits).numpy()[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probabilities before scaling:         [0.10650698 0.10650698 0.78698604]\n",
            "Probabilities after scaling with 0.5: [0.21194156 0.21194156 0.57611688]\n",
            "Probabilities after scaling with 0.1: [0.31042377 0.31042377 0.37915245]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeUm-fR6SIXp",
        "colab_type": "code",
        "outputId": "7d1b7fa8-a0a1-4eff-985f-2851cff0f379",
        "colab": {}
      },
      "source": [
        "# more predictable, alpha = 2.0\n",
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='The island', \n",
        "             scale_factor=2.0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The island was so as to discover the position of the darkness there.\n",
            "\n",
            "The ground was about to death the man had been so struck the colonists have been able to speak a little by returning to the corral. The next day the summer heard might be supposed that the first time on the shore, and the captain proved the cart of the colonists the stranger was towards the\n",
            "colonists, who were very simple to salm a little beach of the corral, the settlers had already proceeded towards the rocks, and they had already sti\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PzI3nhQSIXs",
        "colab_type": "code",
        "outputId": "e3b6bb9d-aa4f-42a6-a9e3-02308b1d2618",
        "colab": {}
      },
      "source": [
        "# more random, alpha = 0.5\n",
        "tf.random.set_seed(1)\n",
        "print(sample(model, starting_str='The island', \n",
        "             scale_factor=0.5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The island\n",
            "happilid a drems parts,\n",
            "withmests? Barmected safed, Lindoency-islew.\n",
            "\n",
            "Top,\n",
            "HiqualshE As culting among Promotion.\n",
            "Criflies verdood. ven,\n",
            "had\n",
            "lastly vivit!\n",
            "Monsh!\n",
            "\n",
            "Coar swimmemsly above Ony indident\n",
            "qumbtelfisking\n",
            "forty-8ther.\n",
            "\n",
            "These trenimostly penered; theanesemonerg.\n",
            "-gamisw, open in his sudden valarmania\n",
            "him leare\n",
            "LebThoastor LarbodDeris raying\n",
            "anchors, unvorunormes an hour, butlo Life polpue escaped by twelve wedcousment.\n",
            "\n",
            "Can ear1-tive, ed Pencroft, who cinnot into nacuounls of\n",
            "severe \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AdrgbJESIXv",
        "colab_type": "text"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/color/32/000000/transformer.png\"/> Understanding language with the Transformer model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtYzcfA0AV_8",
        "colab_type": "text"
      },
      "source": [
        "A recent architecture has recently emerged that has been shown to outperform the RNN-based `seq2seq` models in several NLP tasks.  The **Transformer** architecture (2017) is capable of modeling global dependencies between input and output sequences.  It is based on the concept of **attention** through the **self-attention mechanism**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp2VNv0jAJku",
        "colab_type": "text"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/color/32/000000/mirror.png\"/> A basic version of self-attention\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdtxXPVnVu_U",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_15.png width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBAvKmkKSIXy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## <img src=\"https://img.icons8.com/color/32/000000/bipolar-disease.png\"/> Multi-head attention and the Transformer block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJ7tL-SeA-hS",
        "colab_type": "text"
      },
      "source": [
        "**Multi-head attention** (MHA) combines multiple self-attention operations together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KQM_iasVxVr",
        "colab_type": "text"
      },
      "source": [
        "<img src=https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch16/images/16_16.png width=\"800\">"
      ]
    }
  ]
}